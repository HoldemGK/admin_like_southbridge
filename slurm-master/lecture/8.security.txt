Тема 8. Безопасность серверов и проектов. Опыт Southbridge

1. Защита SSH. Использование OTP для доступа к серверам. Скрипты и их применение

Перед началом данной темы стоит отметить что в Southbridge мы очень ответственно подходим к вопросам безопасности и постоянно развиваем данное направление. Одним их основных инструментов обеспечения безопасности является организация доступа к серверам компании и клиентов. Выглядит это следующим образом:

Точка входа, которую мы называем (админ-бокс). У каждого администратора в компании есть персональная виртуальная машина через которую осуществляется вся работа, администратор подключается к этой виртуальной машине под своим пользователем. Вход осуществляется по паролю и одноразовому паролю с помощью PAM модуля google аутентификации, с данным модулем вы можете ознакомиться на Github. Установка модуля не занимает много времени, но выгода которую вы получите при его использовании будет огромной. Таким образом для того что бы попасть в админ-бокс, нам нужно, во первых, заполучить пароль администратора, во вторых доступ к его гаджету на котором установлена программа генерации одноразовых паролей. Учетные записи администраторов не имеют прав root на админ-боксах, таким образом они не смогут отключить авторизацию через одноразовые пароли и выполнить другие запрещенные действия. Это первый этап, переходим к доступу до серверов клиентов. Во первых доступ к серверам клиентов осуществляется по запароленным ssh-ключам для удобства авторизации, при каждом входе в админбокс процесс активации ключа запускается автоматически, запускается ssh-agent и добавляется ключ, администратор вводит пароль от ключа и с этого момента может попасть на любой сервер клиента к которому имеет доступ. 

Код выполняющий данную функцию вы можете в репозитории red-slurm

Доступ по SSH ко всем серверам клиентов разрешен только с IP адресов компании, это также является дополнительным источником безопасности. Работает это так: доступ управляется отдельной цепочкой iptables.ssh

1. стартап скрипт iptables.ssh заливается на сервер с помощью системы управления конфигурацией
2. В /etc/ssh.iptables.cfg - список адресов и сетей с которых разрешен коннект (он является постоянным и автоматически затирается системой управления конфигурацией при изменении)
3. В /etc/ssh.iptables.local.cfg - локальный список разрешенных адресов (создается руками на сервере или системой управления конфигурацией)

Конечно же существуют серверы к которым нельзя ограничить доступ белым списком IP адресов, для таких серверов дополнительной защитой выступает пакет denyhosts который умеет автоматически блокировать адреса при некотором количестве неудачных попыток авторизации. Он также поддерживает белые и черные списки.

Подобная структура позволяет эффективно организовать процесс управления доступа к серверам, в случаях когда мы прощаемся с сотрудником этот доступ также просто отбирается, достаточно выключить виртуальную машину администратора, с этого момента он не сможет попасть ни на один сервер компании и клиента. Дополнительно проводиться чистка учетных записей администратора с серверов клиентов и компании с помощью систем управления конфигурацией, закрывается доступ к Redmine и Gitlab.

Дополнительно есть несколько полезных самописных скриптов которые мы также активно используем. Первый из них называется Sudo user check. Скрипт предназначен для проверки учётных записей пользователей с правами администратора. Скрипт проверяет наличие файла /root/.sudocheck, в котором содержатся пользователи, которым разрешён доступ через sudo, либо пользователей, которые добавлены в группу wheel. Учётные записи этих пользователей будут пропускаться при проверке. Проверяются файлы конфигурации /etc/passwd, /etc/group и файлы в папке /etc/sudoers.d/*, если они есть. Таким образом мы контролируем пользователей с правами root на серверах.

Второй скрипт называется sshd check и он контролирует состояние демона SSH, следит что бы пакет и его содержимое не менялись а конфигурационные файлы соответствовали стандартам, что гарантирует нам стабильную работу SSH на серверах

2. Защита сайта от DDoS-атак

Атака, во время которой пользователи не могут получить доступ к тем или иным ресурсам, называют DDoS-атакой, или проблемой типа «Отказ в обслуживании». Основная особенность таких хакерских атак – это одновременные запросы с большого числа компьютеров по всему миру.

Зараженный компьютер, становиться подобием «зомби», а хакеры, используя несколько сотен, а то и десятки тысяч таких «зомби», вызывают сбой в работе ресурсов (отказ в обслуживании).  Далее мы поговори о «ДДоС-атаке - что это, как защититься, каковы её последствия и какими средствами она проводится?» 

ДДоС-атаки имеют свои классификационные признаки.

Полосы пропускания. Сегодня практически каждое компьютерное место оборудовано либо локальной сетью, либо просто подключено к интернету. Поэтому нередки случаи сетевого флуда – большого количества запросов с неправильно сформированной и бессмысленной системой к конкретным ресурсам или оборудованию с целью его последующего отказа или сбоя (каналы связи, жёсткие диски, память и др.).

Исчерпание системы. Такая ДДоС-атака на сервер проводится для захвата физической памяти, процессорного времени и других системных ресурсов, из-за отсутствия которых атакуемому объекту просто нет возможности полноценно работать.

Зацикливание. Бесконечная проверка данных и другие циклы, действующие «по кругу», заставляют объект тратить массу ресурсов, тем самым засоряя память до полного её исчерпания.

Ложные атаки. Такая организация направлена на ложное срабатывание систем защиты, что в итоге приводит к блокировке некоторых ресурсов.

HTTP протокол. Хакеры посылают малоёмкие HTTP-пакеты с особым шифрованием, ресурс, естественно, не видит, что на него организованна ДДоС-атака, программа для сервера, выполняя свою работу, отсылает в ответ пакеты гораздо большей ёмкости, тем самым засоряя полосу пропускания жертвы, что приводит опять таки к отказу работы сервисов. 

Смурф-атака. Это один из самых опасных видов. Хакер по широковещательному каналу отправляет жертве поддельный ICMP-пакет, где адрес жертвы подменяется адресом злоумышленника, и все узлы начинают присылать ответ на пинг-запрос. Данная ДДоС-атака – направленна на использование большой сети, т. е. запрос, обработанный посредством 100 компьютеров, будет усилен в 100 раз.

UDP-флуд. Этот вид атаки чем-то схож с предыдущим, но вместо ICMP-пакетов злоумышленники используют UDP-пакеты. Суть этого метода в том, чтобы подменить IP-адрес жертвы на адрес хакера и полностью загрузить полосу пропускания, что также приведёт к сбою системы.

SYN-флуд. Злоумышленники пытаются одновременно запустить большое количество TCP-соединений через SYN-канал с неверным или вовсе отсутствующим обратным адресом. После нескольких таких попыток большинство операционных систем ставят в очередь проблемное соединение и только после энного числа попыток его закрывают. Поток SYN-канала довольно большой, и вскоре, после множества таких попыток, ядро жертвы отказывается открывать любое новое соединение, блокируя работу всей сети.

«Тяжёлые пакеты». Данный вид даёт ответ на вопрос: «Что такое ДДоС-атака сервера?» Хакеры отсылают пакеты серверу пользователя, но насыщение полосы пропускания не происходит, действие направлено только на процессорное время. В результате такие пакеты приводят к сбою в системе, а она, в свою очередь, отказывает в доступе к своим ресурсам. 

Лог-файлы. Если система квотирования и ротации имеют бреши в защите, то злоумышленники могут отправлять большие по объёму пакеты, занимая тем самым всё свободное место на жёстких дисках сервера.

Программный код. Хакеры с большим опытом могут полностью изучить структуру сервера жертвы и запустить специальные алгоритмы (ДДоС-атака – программа-эксплоит). Такие атаки главным образом направлены на хорошо защищённые коммерческие проекты предприятий и организации различных сфер и областей. Злоумышленники находят бреши в программном коде и запускают недопустимые инструкции или другие исключительные алгоритмы, которые приводят к аварийной остановке системы или службы.

Борьба с DDoS-атаками — работа не только сложная, но и увлекательная. Что делать, если пришел DDoS? Традиционная техника самообороны — почитать лог-файл HTTP-сервера, написать паттерн для grep (отлавливающий запросы ботов) и забанить всех, кто под него подпадет. Эта методика сработает… если повезет. Ботнеты бывают двух типов, оба опасны, но по-разному. Один целиком приходит на сайт моментально, другой — постепенно. Первый убивает все и сразу, зато в логах появляется весь полностью, и если вы их проgrepаете и забаните все IP-адреса, то вы — победитель. Второй ботнет укладывает сайт нежно и осторожно, но банить вам его придется, возможно, на протяжении суток. Любому администратору важно понимать: если планируется бороться grep’ом, то надо быть готовым посвятить борьбе с атакой пару дней. Далее будут советы о том, куда можно заранее подложить соломки, чтобы не так больно было падать.

Использовать модуль testcookie

Пожалуй, самый главный, действенный и оперативный рецепт. Если на ваш сайт приходит DDoS, то максимально действенным способом дать отпор может стать модуль testcookie-nginx. Идея простая. Чаще всего боты, реализующие HTTP-флуд, довольно тупые и не имеют механизмов HTTP cookie и редиректа. Иногда попадаются более продвинутые — такие могут использовать cookies и обрабатывать редиректы, но почти никогда DoS-бот не несет в себе полноценного JavaScript-движка (хотя это встречается все чаще и чаще). Testcookie-nginx работает как быстрый фильтр между ботами и бэкендом во время L7 DDoS-атаки, позволяющий отсеивать мусорные запросы. В эти проверки входит умеет ли клиент выполнять HTTP Redirect, поддерживает ли JavaScript, тот ли он браузер, за который себя выдает (поскольку JavaScript везде разный и если клиент говорит, что он, скажем, Firefox, то мы можем это проверить). Проверка реализована с помощью кукисов с использованием разных методов:

* «Set-Cookie» + редирект с помощью 301 HTTP Location;
* «Set-Cookie» + редирект с помощью HTML meta refresh;
* произвольным шаблоном, причем можно использовать JavaScript.

Чтобы избежать автоматического парсинга, проверяющая кука может быть зашифрована с помощью AES-128 и позже расшифрована на клиентской стороне JavaScript. Примечательно, что начать использовать testcookie-nginx крайне просто. Разработчик, в частности, приводит несколько понятных примеров использования (на разные случаи атаки) с семплами конфигов для nginx.

Помимо достоинств, у testcookie есть и недостатки:

* режет всех ботов, в том числе Googlebot. Если вы планируете оставить testcookie на постоянной основе, убедитесь, что вы при этом не пропадете из поисковой выдачи;
* создает проблемы пользователям с браузерами Links, w3m и им подобными;
* не спасает от ботов, оснащенных полноценным браузерным движком с JavaScript.

Словом, testcookie_module не универсален. Но от ряда вещей, таких как, например, примитивные инструментарии на Java и C#, он помогает. Таким образом вы отсекаете часть угрозы.

Код 404

Целью DDoS’еров часто становится наиболее ресурсоемкая часть сайта. Типичный пример — поиск, который выполняет сложные запросы к базе. Естественно, этим могут воспользоваться злоумышленники, зарядив сразу несколько десятков тысяч запросов к поисковому движку. Что мы можем сделать? Временно отключить поиск. Пускай клиенты не смогут искать нужную информацию встроенными средствами, но зато весь основной сайт будет оставаться в работоспособном состоянии до тех пор, пока вы не найдете корень всех проблем. Nginx поддерживает нестандартный код 444, который позволяет просто закрыть соединение и ничего не отдавать в ответ

Таким образом можно, например, оперативно реализовать фильтрацию по URL. Если вы уверены, что запросы к location /search приходят только от ботов (например, ваша уверенность основана на том, что на вашем сайте вообще нет раздела /search), вы можете установить на сервер пакет ipset и забанить ботов простым shell-скриптом

Если формат лог-файлов нестандартный или требуется банить по иным признакам, нежели статус ответа, — может потребоваться заменить cut на регулярное выражение.

Баним по геопризнаку

Нестандартный код ответа 444 может пригодиться еще и для оперативного бана клиентов по геопризнаку. Вы можете жестко ограничить отдельные страны, от которых испытываете неудобство. Скажем, вряд ли у интернет-магазина фотоаппаратов из Ростова-на-Дону много пользователей в Египте. Это не очень хороший способ (прямо скажем — отвратительный), поскольку данные GeoIP неточны, а ростовчане иногда летают в Египет на отдых. Но если вам терять нечего, то следуйте инструкциям:

1. Подключите к nginx GeoIP-модуль (wiki.nginx.org/HttpGeoipModule).
2. Выведите информацию о геопривязке в access log.
3. Далее, модифицировав приведенный выше шелл-скрипт, проgrepайте accesslog nginx’а и добавьте отфутболенных по географическому признаку клиентов в бан.

Если, к примеру, боты по большей части были из Китая, то это может помочь.

Диагностика проблемы

Сайт не работает — почему? Его DDoS’ят или это баг движка, не замеченный программистом? Неважно. Не ищите ответа на этот вопрос. Если вы считаете, что ваш сайт могут атаковать, обратитесь к компаниям, предоставляющим защиту от атак, — у ряда анти-DDoS-сервисов первые сутки после подключения бесплатны — и не тратьте больше время на поиск симптомов. Сосредоточьтесь на проблеме. Если сайт работает медленно или не открывается вообще, значит, у него что-то не в порядке с производительностью, и — вне зависимости от того, идет ли DDoS-атака или нет, — вы, как профессионал, обязаны понять, чем это вызвано.

Юзайте профайлер и отладчик

Для наиболее распространенной платформы создания веб-сайтов — PHP + MySQL — узкое место можно искать с помощью следующих инструментов:

* профайлер Xdebug покажет, на какие вызовы приложение тратит больше всего времени;
* встроенный отладчик APD и отладочный вывод в лог ошибок помогут выяснить, какой именно код выполняет эти вызовы;
* в большинстве случаев собака зарыта в сложности и тяжеловесности запросов к базе данных. Здесь поможет встроенная в движок базы данных SQL-директива explain.

Если сайт лежит навзничь и вы ничего не теряете, отключитесь от сети, посмотрите логи, попробуйте их проиграть. Если не лежит, то походите по страницам, посмотрите на базу.

Пример приведен для PHP, но идея справедлива для любой платформы. Разработчик, пишущий программные продукты на каком бы то ни было языке программирования, должен уметь оперативно применять и отладчик, и профилировщик.

Анализируйте ошибки

Проанализируйте объем трафика, время ответа сервера, количество ошибок. Для этого смотрите логи. В nginx время ответа сервера фиксируется в логе двумя переменными: request_time и upstream_response_time. Первая — это полное время выполнения запроса, включая задержки в сети между пользователем и сервером; вторая сообщает, сколько бэкенд (Apache, php_fpm, и так далее…) выполнял запрос. Значение upstream_response_time чрезвычайно важно для сайтов с большим количеством динамического контента и активным общением фронтенда с базой данных, им нельзя пренебрегать. 

Отслеживайте количество запросов в секунду

Также посмотрите на число запросов в секунду. В случае nginx вы можете примерно оценить эту величину следующей shell-командой (переменная ACCESS_LOG содержит путь к журналу запросов nginx)

По сравнению с нормальным для этого времени дня уровнем количество запросов в секунду может как падать, так и расти. Растут они в случае, если пришел крупный ботнет, а падают, если пришедший ботнет обрушил сайт, сделав его полностью недоступным для легитимных пользователей, и при этом ботнет статику не запрашивает, а легитимные пользователи запрашивают. Падение количества запросов наблюдается как раз за счет статики. Но, так или иначе, мы ведем речь о серьезных изменениях показателей. Когда это происходит внезапно — пока вы пытаетесь решить проблему своими силами и если не видите ее сразу в логе, лучше быстро проверьте движок и параллельно обратитесь к специалистам.

Лимитируем ресурсы (размеры буферов) в nginx

Про что нужно помнить в первую очередь? Каждый ресурс имеет лимит. Прежде всего это касается оперативной памяти. Поэтому размеры заголовков и всех используемых буферов нужно ограничить адекватными значениями на клиента и на сервер целиком. Их обязательно нужно прописать в конфиге nginx.

client_header_buffer_size__ Задает размер буфера для чтения заголовка запроса клиента. Если строка запроса или поле заголовка запроса не помещаются полностью в этот буфер, то выделяются буферы большего размера, задаваемые директивой large_client_header_buffers.

large_client_header_buffers Задает максимальное число и размер буферов для чтения большого заголовка запроса клиента.

client_body_buffer_size Задает размер буфера для чтения тела запроса клиента. Если тело запроса больше заданного буфера, то все тело запроса или только его часть записывается во временный файл.

client_max_body_size Задает максимально допустимый размер тела запроса клиента, указываемый в поле «Content-Length» заголовка запроса. Если размер больше заданного, то клиенту возвращается ошибка 413 (Request Entity Too Large).

Настраиваем тайм-ауты в nginx

Ресурсом является и время. Поэтому следующим важным шагом должна стать установка всех тайм-аутов, которые опять же очень важно аккуратно прописать в настройках nginx.

* reset_timedout_connection on; Помогает бороться с сокетами, зависшими в фазе FIN-WAIT.
* client_header_timeout Задает тайм-аут при чтении заголовка запроса клиента.
* client_body_timeout Задает тайм-аут при чтении тела запроса клиента.
* keepalive_timeout Задает тайм-аут, в течение которого keep-alive соединение с клиентом не будет закрыто со стороны сервера. Многие боятся задавать здесь крупные значения, но мы не уверены, что этот страх оправдан. Опционально можно выставить значение тайм-аута в HTTP-заголовке Keep-Alive
* send_timeout Задает тайм-аут при передаче ответа клиенту. Если по истечении этого времени клиент ничего не примет, соединение будет закрыто.

Сразу вопрос: какие параметры буферов и тайм-аутов правильные? Универсального рецепта тут нет, в каждой ситуации они свои. Но есть проверенный подход. Нужно выставить минимальные значения, при которых сайт остается в работоспособном состоянии (в мирное время), то есть страницы отдаются и запросы обрабатываются. Это определяется только тестированием — как с десктопов, так и с мобильных устройств. Алгоритм поиска значений каждого параметра (размера буфера или тайм-аута):

1. Выставляем математически минимальное значение параметра.
2. Запускаем прогон тестов сайта.
3. Если весь функционал сайта работает без проблем — параметр определен. Если нет — увеличиваем значение параметра и переходим к п. 2.
4. Если значение параметра превысило даже значение по умолчанию — это повод для обсуждения в команде разработчиков.

В ряде случаев ревизия данных параметров должна приводить к рефакторингу/редизайну сайта. Например, если сайт не работает без трехминутных AJAX long polling запросов, то нужно не тайм-аут повышать, а long polling заменять на что-то другое — ботнет в 20 тысяч машин, висящий на запросах по три минуты, легко убьет среднестатистический дешевый сервер.

Готовим ОС

Помимо тонкой настройки nginx, нужно позаботиться о настройках сетевого стека системы. По меньшей мере — сразу включить tcp_syncookies в sysctl, чтобы разом защитить себя от атаки SYN-flood небольшого размера.

Тюним ядро

Обратите внимание на более продвинутые настройки сетевой части (ядра) опять же по тайм-аутам и памяти. Есть более важные и менее важные. В первую очередь надо обратить внимание на:

* net.ipv4.tcp_fin_timeout Время, которое сокет проведет в TCP-фазе FIN-WAIT-2 (ожидание FIN/ACK-сегмента).
* net.ipv4.tcp_{,r,w}mem Размер приемного буфера сокетов TCP. Три значения: минимум, значение по умолчанию и максимум.
* net.core.{r,w}mem_max То же самое для не TCP буферов.

При канале в 100 Мбит/с значения по умолчанию еще как-то годятся; но если у вас в наличии хотя бы гигабит в cекунду, то лучше использовать что-то вроде того что указано на слайде

Ревизия /proc/sys/net/**

Идеально изучить все параметры /proc/sys/net/**. Надо посмотреть, насколько они отличаются от дефолтных, и понять, насколько они адекватно выставлены. Linux-разработчик (или системный администратор), разбирающийся в работе подвластного ему интернет-сервиса и желающий его оптимизировать, должен с интересом прочитать документацию всех параметров сетевого стека ядра. Возможно, он найдет там специфические для своего сайта переменные, которые помогут не только защитить сайт от злоумышленников, но и ускорить его работу.

Подручными средствами можно справиться лишь с атаками сравнительно небольшого размера, когда все что я рассказал раннее не помогает на помощь приходят провайдеры предоставляющие услуги защиты от DDoS, на рынке их существует достаточно много, основные из них: CloudFlare, Qrator, SkyPark CDN, Akamai, StormWall

Принцип работы у большинства из них схож, тоже самое касается настройки защиты. Провайдер выделяет вам защищенный IP адрес, вы направляете запись в DNS вашего сайта на этот IP, в панели управления указываете IP адрес реального сервера. Таким образом весь трафик который будет приходить на ваш сайт в том числе и атакующий сначала будет проходить через провайдера защиты, он отфильтрует все нелегитимные запросы, а легитимные перенаправит на ваш сервер. 

3. Скрипты защиты от http-флуда, сканирования портов, проверки целостности пакетов

Для защиты сайтов клиентов от http-флуда используется самописный скрипт который умеет по логам веб-сервера устанавливать факт флуда на сайт и блокировать адреса. При блокировке скрипт умеет слать уведомления на email. Естественно подобное решение не сможет отразить более менее внушительную атаку, т.к. оно больше призвано защищать от парсинга сайта. Скрипт работает следующим образом: он парсит лог-файл веб-сервера и если кол-во совпадений по запросам из лога с одного IP из последних 10.000 записей совпадает указанному в конфиге значению - IP блокируется. 

Сканирование портов

Для обеспечения безопасности при использовании сети Интернет необходимо следить за отрытыми портами на сервере. В противном случае система может быть взломана злоумышленниками, которые прослушивают открытые порты и через них внедряют вредоносный код. Следить нужно за абсолютно каждым портом, и всегда закрывать порты которые не должны быть доступны внешнему миру, в нашей практике мы очень часто сталкиваемся с тем что на сервере клиента когда он приходит на поддержку открыто внешнему миру все что только можно и базы данных и memcache/redis порты внутренних сервисов и так далее, как вы понимаете это серьезная угроза безопасности проекта, поэтому в целях обеспечения безопасности наших клиентов мы разработали простой скрипт который постоянно сканирует TCP и UDP порты на хостах из списка. И в случае обнаружения проблем ставит задачу в Redmine.

Скрипт берёт список хостов из файла, и сканирует диапазон, указанный в переменной. Скрипт выводит результат на экран, и в файл. В переменной $HOST_TIMEOUT указывается время, после которого скрипт остановит сканирование хоста. В случае если все порты на хосте закрыты, скрипт пингует хост. Если пинг хоста успешный - выводится сообщение "All ports closed". Если пропинговать хост не удалось - выводится сообщение "Host is down?". При выполнении UDP сканирования необходимо запускать скрипт под рутом. UDP сканирование сильно увеличивает время, необходимое для сканирования хоста, поэтому переменной $SCAN_PORTS необходимо указывать достаточно высокое значение, или сканирование хоста завершится по таймауту, и скрипт выдаст сообщение "All ports closed".

Проверка целостности пакетов

Скрипт fix-rpm.sh служит для сверки хеш-сумм файлов, записанных в установочном файле пакета, с хеш-суммами файлов пакета, расположенными на диске. При повреждении/изменении файла скрипт предпринимает попытку переустановить пакет, а затем выполнить апгрейд пакета. В случае, если процесс переустановки проходит без проблем, скрипт завершает работу. В случае если скрипт по каким-либо причинам не может выполнить переустановку или апгрейд пакета, либо как минимум один пакет входит в список исключений пакетов, по которым не выполняется обновление- формируется тикет в redmine, который подразумевает вмешательство системного администратора. Системный администратор должен сначала попробовать переустановить пакет, если переустановка невозможна - выполняется апгрейд пакета.

Расшифровка вывода rpm -Va

Скрипт использует данные, выводимые утилитой rpm c ключами -V (выполняет проверку пакетов на целостность) и -a (применимо ко всем пакетам). При проверке данные выводятся в формате указанном на слайде

Может быть три файла конфигурации скрипта:

* fix-rpm.conf.dist - файл конфигурации, устанавливаемый со скриптом по умолчанию;
* fix-rpm.conf - файл конфигурации для внесений изменений через слак;
* fix-rpm.local.conf - файл конфигурации для локальных изменений.

В файле конфигурации есть две переменные, EXCLUDE_PACKET и EXCLUDE_FILE.

EXCLUDE_PACKET позволяет исключать пакеты из обновления, т.е., например, пакет php-fpm будет пропущен, т.к. он подпадает под маску 'php'. Если встречается как минимум один такой пакет, то он пропускается, но при этом формируется тикет по данной проблеме.

EXCLUDE_FILE при добавлении пути в эту переменную, пакет, который содержит файлы по этому пути не проверяется, тикет не формируется. Этот вариант подходит для пакетов, которые были установлены вручную и/или отсутствуют в репозитории, либо когда файлы были намеренно изменены, и клиент настаивает на том, чтобы их сохранить в таком виде.

Для описания исключений используется perl regexp. Для разграничения выражений используется символ '|' (пайп), соответственно строка в локальном файле исключений всегда должна начинаться с этого символа.

4. Скрипты проверки ПО на уязвимости и автоматическое обновление

Для проверки сервера на уязвимости мы используем скрипт vulners-scanner вы можете найти его на GitHub, скрипт написан на Python и работает следующим образом. Опрашивает API vulners.com. Обнаруживает тип ОС, собирает установленные пакеты и проверяет в ней уязвимости. Скрипт поддерживает RHEL и Debian based системы. Работа со скриптом также максимально простая, достаточно скачать его с GitHub, проверить что файл является исполняемым и запустить, пример вывода вы можете видеть на слайде.

Также мы используем небольшой самочинный скрипт на bash который пользуется стандартной функциональностью пакетного менеджера yum. yum list-security
Команда возвращает список пакетов для которых есть обновления безопасности и ставит задачу в Redmine после чего выполняется обновление пакетов.