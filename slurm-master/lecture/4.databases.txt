Тема 4. Базы данных. Опыт и практика Southbridge

1. Принятые стандарты настройки

Поговорим о стандартах настройки баз данных. Здесь на самом деле все просто. Для установки баз данных не важно будь то PostgreSQL, MySQL, Redis либо что-то еще всегда используются только официальные репозитории и установка из пакетов, мы никогда не ставим базы данных из исходников, и вам этого делать не рекомендую, если по каким либо причинам вам потребуется использовать базу данных с другими параметрами сборки лучше собрать для этого собственный пакет и положить к себе в репозиторий. Это первое. Во вторых расположение файлов конфигурации, каталога с данными, скриптов мониторинга и бэкапов. Абсолютно на каждом сервере который мы обслуживаем мы придерживаемся четкой структуры, и когда мы подключаемся например к серверу на котором установлен MySQL мы заранее знаем где что лежит, и не тратим время на то чтобы понять как же тут все работает. Обязательно настраивается мониторинг, для этого используются как самописные скрипты которые работают непосредственно на сервере так и готовые решения такие как Zabbix. Абсолютно на каждом сервере используется одинаковый скрипт бэкапа, он на каждом сервере лежит по одинаковому пути и запускается одинаковой крон задачей, отличаются только параметры запуска скрипта, в зависимости от типа бэкапа который мы хотим запустить, файл с этими настройками также всегда лежит в одном месте. Есть стандарт добавления и удаления пользователей на сервер.

Давайте перейдем непосредственно к базам данных и посмотрим как это все выглядит в реальной жизни.

2. MySQL. Установка, настройка, тюнинг, применение изменений без даунтайм

Начнем с MySQL как наиболее распространенной базе данных, по моим наблюдения её используют около 80% всех наших клиентов.

Помимо оригинальной версии MySQL существует также достаточно большое количество форков, например MariaDB или Percona. О них мы поговорим немного позже. Давайте для начала разберемся что из себя представляет MySQL и как он работает.

Для того чтобы максимально эффективно использовать MySQL, нужно разобраться в ее устройстве. Гибкость системы проявляется во многом. Например, вы можете настроить ее для работы на различном оборудовании и поддержки разных типов данных. Однако самой необычной и важной особенностью MySQL является такая архитектура подсистемы хранения, в которой обработка запросов и другие серверные задачи отделены от хранения и извлечения данных. Подобное разделение задач позволяет выбирать способ хранения данных, а также настраивать производительность, ключевые характеристики и так далее. 

Логическая архитектура MySQL 

Чтобы хорошо понимать работу сервера, нужно иметь представление о взаимодействии его компонентов. На слайде представлен логический вид архитектуры MySQL. 

На верхнем уровне располагаются службы, не являющиеся уникальными компонентами MySQL. Они необходимы большинству сетевых клиент-серверных инструментов или серверов: для обслуживания соединений, аутентификации, обеспечения безопасности и так далее.

Второй уровень намного интереснее. Здесь находится бОльшая часть «мозгов» MySQL: код для обработки, анализа, оптимизации и кэширования запросов, а также все встроенные функции (например, функции даты/времени, математические и функции шифрования). Здесь также расположены все инструменты, используемые в подсистемах хранения, например хранимые процедуры, триггеры и представления.

Третий уровень содержит подсистемы хранения данных. Они отвечают за хранение всех данных в MySQL и их извлечение. Подобно различным файловым системам, доступным для Linux, каждая подсистема хранения данных имеет как сильные, так и слабые стороны. Сервер взаимодействует с ними через API подсистемы хранения данных. Этот интерфейс скрывает различия между такими подсистемами и делает их практически прозрачными на уровне запросов. API содержит пару десятков низкоуровневых функций, выполняющих операции типа «начать транзакцию» или «извлечь строку с таким первичным ключом». Подсистемы хранения не анализируют запросы SQL и не взаимодействуют друг с другом, они просто отвечают на исходящие от сервера запросы. 

Управление соединениями и их безопасность 

Для каждого клиентского соединения внутри серверного процесса выделяется отдельный поток. Запросы соединения выполняются только внутри этого потока, который, в свою очередь, выполняется одним ядром или процессором. Сервер кэширует потоки, поэтому их не нужно создавать или уничтожать для каждого нового соединения.

Когда приложения подключаются к серверу MySQL, он должен их аутентифицировать. Аутентификация выполняется на основе имени пользователя, адреса хоста, с которого происходит соединение, и пароля. При соединении по протоколу (SSL) можно использовать сертификаты. 

После того как клиент подключился, сервер проверяет наличие необходимых привилегий для каждого запроса (например, может ли клиент использовать команду SELECT применительно к таблице Country базы данных world). 

Оптимизация и выполнение 

MySQL анализирует запросы для создания внутренней структуры (дерева разбора), а затем выполняет оптимизации. Это могут быть переписывание запроса, определение порядка чтения таблиц, выбор используемых индексов и так далее. Через специальные ключевые слова в запросе вы можете передать оптимизатору подсказки и тем самым повлиять на процесс принятия решения. Или обратиться к серверу за объяснением различных аспектов оптимизации. Это позволит вам понять, какие решения принимает сервер, и даст ориентир для изменения запросов, схем и настроек, чтобы добиться максимальной эффективности работы.

Прежде чем анализировать запрос, сервер обращается к кэшу запросов, в котором могут храниться только команды SELECT вместе с наборами результатов. Если поступает запрос, идентичный уже имеющемуся в кэше, серверу не нужно выполнять анализ, оптимизацию или сам запрос - он может просто отправить в ответ сохраненный на­бор результатов.

Подробнее анализ запросов и их оптимизацию мы рассмотрим немного позже.

Управление конкурентным доступом

Задача управления конкурентным доступом возникает в тот момент, когда нескольким запросам необходимо одновременно изменить данные. 

В качестве примера будем использовать ящик электронной почты в системе UNIX. Классический файл формата mbox очень прост. Все сообщения в почтовом ящике mbox расположены одно за другим, так что читать и анализировать почтовые сообщения очень просто. Это также существенно упрощает доставку почты: достаточно добавить новое сообщение в конец файла. 

Но что происходит, когда два процесса пытаются одновременно поместить сообщения в почтовый ящик? Очевидно, что чередование строк этих сообщений приведет к повреждению файла. Чтобы предотвратить это, правильно работающие почтовые системы используют блокировку. Если клиент пытается отправить новое сообщение в тот момент, когда почтовый ящик заблокирован, ему придется подождать, пока он не сможет сам использовать блокировку, чтобы отправить сообщение. 

Эта схема довольно хорошо работает, но не поддерживает конкурентный доступ. Поскольку в любой момент времени только один процесс может изменять содержимое почтового ящика, такой подход создает проблемы при работе с большими почтовыми ящиками. 

Блокировки чтения/записи 

Чтение из почтового ящика не вызывает таких проблем. Ничего страшного, если несколько клиентов одновременно считывают информацию из одного и того же почтового ящика. Раз они не вносят изменений, ничего плохого случиться не должно. Но что произойдет, если кто-нибудь попытается удалить сообщение в тот момент, когда программы читают письма из почтового ящика? Возможны различные варианты развития ситуации, но программа чтения может получить почтовый ящик в поврежденном или неструктурированном виде. Поэтому для обеспечения безопасности даже чтение информации из почтового ящика требует определенных предосторожностей. 

Если представить, что почтовый ящик - это таблица базы данных, а каждое почтовое сообщение - строка, легко увидеть, что и в этом контексте актуальна та же проблема. Во многих смыслах почтовый ящик является простой таблицей базы данных. Модификация строк в такой базе очень похожа на удаление или изменение содержимого сообщений в файле почтового ящика. 

У классической задачи управления конкурентным доступом довольно простое решение. В системах, которые имеют дело с конкурентным доступом для чтения/записи, чаще всего реализуется система блокирования, содержащая два типа блокировок. Обычно их называют разделяемыми блокировками и монопольными блокировками, или блокировками чтения и блокировками записи.
 
Не вдаваясь в подробности технологии блокирования, данную концепцию можно описать следующим образом. Блокировки чтения ресурса являются разделяемыми или взаимно неблокирующими: множество клиентов могут производить считыва­ние из ресурса в одно и то же время, не мешая друг другу. Блокировки записи, на­против, являются эксклюзивными. Другими словами, они исключают возможность установки блокировки чтения и других блокировок записи, поскольку единственной безопасной политикой является наличие только одного клиента, выполняющего запись в данный момент времени, и предотвращение во время этого всех операций чтения. 

В базах данных блокировки происходят постоянно: MySQL запрещает одному кли­енту считывать данные, когда другой клиент их изменяет. Управление блокировками осуществляется внутри СУБД в соответствии с принципами, которые достаточно прозрачны для клиентов.

Табличные блокировки 

Табличная блокировка является базовой стратегией блокировки в MySQL. Кроме того, у нее самые низкие издержки. Табличная блокировка аналогична рассмотренным ранее блокировкам почтового ящика - блокируется вся таблица. Когда клиент хочет сделать запись в таблицу (вставку, удаление, обновление и тому подобное), он получает блокировку на запись для всей таблицы. Это предотвращает все остальные операции чтения и записи. Когда никто не выполняет запись, любой клиент может получить блокировку на чтение, которая не конфликтует с другими подобными блокировками. 

У табличных блокировок есть вариации для обеспечения высокой производительности в различных ситуациях. Например, табличные блокировки READ LOCAL разрешают выполнять некоторые типы параллельных операций записи. Кроме того, блокировки записи имеют более высокий приоритет, чем блокировки чтения. По­ этому запрос блокировки записи будет помещен в очередь перед уже находящимися там запросами блокировки чтения. 

Подсистемы хранения также могут управлять собственными блокировками. 

Построчные блокировки 

Построчные блокировки обеспечивают лучшее управление конкурентным доступом (и влекут максимальные издержки). Блокировка на уровне строк доступна, в частно­сти, в подсистемах хранения InnoDB и XtгaDB. Построчные блокировки реализуются подсистемами хранения данных, а не сервером. Сервер ничего не знает о блокировках, реализованных подсистемой хране­ния данных, и, как вы узнаете далее, все подсистемы хранения данных реализуют блокировки по-своему. 

Транзакции 

Транзакция представляет собой группу запросов SQL, обрабатываемых атомарно, то есть как единое целое. Если подсистема базы данных может выполнить всю груп­пу запросов, она делает это, но если какой-либо запрос не может быть выполнен в результате сбоя или по иной причине, ни один запрос группы не будет выполнен. Все или ничего. 

Ведение журнала транзакций 

Ведение журнала помогает сделать транзакции более эффективными. Вместо обнов­ления таблиц на диске после каждого изменения подсистема хранения данных может изменить находящуюся в памяти копию данных. Это происходит очень быстро. Затем подсистема хранения запишет сведения об изменениях в журнал транзакции, который хранится на диске и поэтому долговечен. Это тоже доволь­но быстрая операция, поскольку добавление событий в журнал сводится к опе­рации последовательного ввода/вывода в пределах ограниченной области диска вместо случайного ввода/вывода в разных местах. Позже процесс обновит табли­цу на диске. Таким образом, большинство подсистем хранения данных, которые используют этот метод (упреждающую запись в журнал), дважды сохраняют из­менения на диске. 

Если сбой произойдет после внесения записи в журнал транзакции, но до обнов­ления самих данных, подсистема хранения может восстановить изменения после перезагрузки сервера. Методы восстановления у каждой подсистемы хранения данных различны. 

Подсистемы хранения в MySQL

MySQL хранит каждую базу данных (также именуемую схемой) как подкаталог своего каталога данных в файловой системе. Когда вы создаете таблицу, MySQL сохраняет ее определение в файле с расширением .frm и именем, совпадающим с именем таблицы. Таким образом, при создании таблицы с именем МуТаblе ее определение сохраняется в файле МуТаblе.frm. Поскольку MySQL использует файловую систему для хранения имен баз данных и определений таблиц, чувствительность к регистру символов зависит от платформы. В MySQL для Windows имена таблиц и баз данных не чувствительны к регистру, а в операционных системах семейства UNIX - чувствительны. Каждая подсистема хранения по-разному записывает табличные данные и индексы, но сервер сам обрабатывает определение таблицы.

Для получения информации о таблицах можете использовать команду SHOW TABLE STATUS. Например, чтобы получить информацию о таблице user, содержащейся в базе данных mysql, выполните команду SHOW TABLE STATUS: 

Как видите, это таблица типа MyISAM. Команда выдала также много дополнительной информации и статистики. Давайте вкратце рассмотрим, что означает каждая строка:

* Name - имя таблицы;  Engine - подсистема хранения. Row_format - формат строки.
* Rows - количество строк в таблице. Для таблиц MyISAM и большинства других подсистем хранения это число всегда точное, для InnoDB- обычно приблизительное; 
* Avg_row_length - количество байтов (в среднем), содержащееся в каждой строке; 
* Data_length - объем данных (в байтах) во всей таблице; 
* Max_data_length - максимальный объем данных, который может хранить эта таблица (зависит от подсистемы хранения); 
* Index_length - объем дискового пространства, занятый индексными данными; 
* Data_free - для таблицы MyISAM показывает объем выделенного пространства, которое в данный момент не используется. Это пространство служит для хранения ранее удаленных строк и может быть задействовано в будущем при выполнении команд INSERT; 
* Auto_increment - следующее значение атрибута AUTO_INCREMENT; 
* Create_time - момент создания таблицы; 
* Update_time - время последнего изменения таблицы; 
* Check_time - время последней проверки таблицы командой СНЕСК TABLE или утилитой myisamchk; 
* Checksum - текущая контрольная сумма содержимого всей таблицы, если ее мож­но определить; 
* Create_options - любые другие параметры, которые были указаны при создании таблицы; 
* Comment - это поле содержит различную дополнительную информацию. Для таблиц MyISAM в нем хранятся комментарии, добавленные при их создании. Если табли­ца использует подсистему хранения InnoDB, здесь указан объем свободного места в табличном пространстве.

Подсистема хранения InnoDB 

InnoDB является транзакционной подсистемой хранения по умолчанию в MySQL, а также наиболее значимой и широко используемой подсистемой хранения в целом. Она была создана для обработки большого количества краткосрочных транзакций, которые выполняются благополучно намного чаще, чем откатываются. Высокая про­изводительность и автоматическое восстановление после сбоя делают ее популярной и для нетранзакционных целей. Вам следует применять InnоDВ для своих таблиц, пока не возникнет необходимость использовать другую подсистему хранения. Если вы хотите изучить подсистемы хранения, не стоит рассматривать их все слишком подробно, но обязательно потратьте время на глубокое ознакомление с InnoDB, чтобы узнать о ней как можно больше. 

История релизов InnoDB довольно сильно запутана, но очень помогает разо­браться в этой подсистеме хранения данных. В 2008 году для версии MySQL 5.1 был выпущен так называемый плагин InnoDB. Это было следующее поколение InnoDB, созданное компанией Oracle, которой в то время принадлежала lnnoDB, но не MySQL. По разным причинам, MySQL продолжала поставлять более старую версию InnoDB, скомпилированную на сервер. Но вы могли по собственному желанию отключить ее и установить новый, более эффективный и лучше масштабируемый плагин InnoDB. В конце концов компания Oracle приобрела компанию Sun Microsystems и, следовательно, СУБД MySQL и удалила старую кодовую базу, заменив ее «плагином» по умолча­нию в версии MySQL 5.5. (Да, это означает, что теперь «плагин» фактически скомпилирован, а не установлен как плагин. Старая терминология изживается с трудом.) 

Современная версия InnoDB, представленная в качестве плагина InnoDB в MySQL 5.1, обеспечивает новый функционал, например построение индексов путем сортировки, возможность удаления и добавления индексов без перестройки всей таблицы, новый формат хранения данных, который предполагает сжатие, новый способ хранения больших объемов данных, таких как столбцы BLOB, и управления форматом файлов. 

InnoDB настолько важна, что в ее разработку внесли свой вклад не только коман­да Oracle, но и многие другие люди и компании, например Google, Percona и Facebook. Некоторые из внесенных ими усовершенствований были включены в официальный исходный код InnoDB, многие другие были немного переработаны командой InnoDB и затем внедрены. В целом развитие InnoDB значительно ускорилось за последние несколько лет, улучшения коснулись инструментария, масштабируемости, способности к изменению конфигурации, производительности, функций и прочих важных вещей. 

InnoDB сохраняет данные в одном или нескольких файлах данных, которые называ­ются табличным пространством (tablespace). Табличное пространство, в сущности, является черным ящиком, которым управляет сама InnoDB. В MySQL 4.1 и более поздних версиях InnoDB может хранить данные и индексы каждой таблицы в от­дельных файлах. Кроме того, она может располагать табличные пространства в «сырых» (неформатированных) разделах диска. Но современные файловые системы делают эту возможность бессмысленной. 

InnoDB использует управление параллельным доступом с помощью многоверсионности для обеспечения высокой степени конкурентности и реа­лизует все четыре стандартных уровня изолированности SQL. Уровнем изоляции по умолчанию является REPEATABLE READ, а стратегия блокировки следующего ключа предотвращает фантомные чтения на этом уровне: вместо того чтобы блокировать только строки, затронутые в запросе, InnoDB блокирует пропуски в структуре ин­декса, предотвращая вставку фантомных строк. 

Таблицы InnoDB строятся на кластеризованных индексах. Структуры индексов в InnoDB значительно отлича­ются от используемых в других подсистемах хранения. В результате эта подсистема обеспечивает более быстрый поиск по первичному ключу. Однако вторичные индексы содержат все столбцы первичного ключа, так что если первичный ключ большой, то все прочие индексы тоже будут большими. Если в таблице планируется много индексов, нужно стремиться к тому, чтобы первичный ключ был небольшим. Формат хранения данных не зависит от платформы. Это означает, что вы можете без проблем скопировать файлы данных и индексов между серверами на различной платформе.
 
InnoDB поддерживает множество внутренних оптимизаций. В их число входят прогнозное упреждающее чтение для предварительной выборки данных с диска, адаптивный хеш-индекс, который автоматически выстраивает хеш-индексы в памяти для обеспечения очень быстрого поиска, и буфер вставок для ускорения операций вставки.

В качестве транзакционной подсистемы хранения InnoDB поддерживает горячее онлайновое резервное копирование с помощью различных меха­низмов, например Percona XtraBackup который мы рассмотрим позднее. В других подсистемах хранения MySQL нет горячих резервных копий - чтобы получить согласованную резервную копию, вам необхо­димо остановить все процессы записи в таблицу, которые при смешанной рабочей нагрузке на чтение и запись обычно заканчиваются также остановкой чтения. 

Прежде чем перейти непосредственно к установке и настройке MySQL сервера давайте поговорим про два основных форка Percona и MariaDB который также активно используются и развиваются

Percona

Откровенно говоря, Percona Server — это не форк. Это сборка обычной MySQL с дополнительными модулями от наших соотечественников Петра Зайцева и Вадима Ткаченко и товарищей. Основная его изюминка — это включенный по умолчанию движок XtraDB storage engine. Отличается от MySQL + InnoDB plugin лучшей производительностью и масштабируемостью, особенно на современных многоядерных серверах. Также улучшена функциональность — больше всякой полезной для оптимизации статистики и прочего. В нем сохранена полная совместимость с таблицами InnoDB, то есть можно переключаться между InnoDB и XtraDB без каких-либо последствий (если не использовать некоторые специфичные для XtraDB функции, типа меньшего размера страницы).

XtraDB основан на коде InnoDB, полностью с ним совместим, но отличается повышенной производительностью, благодаря интеграции патчей от компаний Google и Percona. В частности, в XtraDB улучшен механизм работы с памятью, добавлена поддержка нескольких потоков чтения и записи, поддержка управления пропускной способностью, реализация упреждающей выборкой данных (read-ahead), адаптивная установка контрольных точек (adaptive checkpointing), улучшена работа подсистемы ввода/вывода InnoDB, расширены возможности по масштабированию, наконец-то появилась поддержка многопоточности и многопроцессорности, добавлены дополнительные возможности для сбора дополнительных данных о работе системы и анализ статистики по ним.

Самым интересным инструментом из тех, что разрабатывает Percona помимо XtraDB, является XtraBackup. Он позволяет, ни много ни мало, снимать бэкапы баз данных на движках InnoDB и XtraDB прямо на лету. Никаких остановок БД, блокировок, зависающих запросов, чем нам всегда был так мил старый добрый mysqldump. Скорость снятия бэкапа — до нескольких раз быстрее по сравнению с классическим дампом. Приятный бонус: если у вас на  MySQL сервере ведутся бинлоги, то он автоматом досчитывает инфу из них в бэкап с момента начала его создания и предоставит инфу о том, на какой позиции этот бэкап останавливается. А это открывает вообще шикарные возможности по масштабированию MySQL в боевых условиях. Поднятие слейва ограничивается всего парой команд и при этом не грозит даунтаймом. Поднятие слейва и работу с XtraBackup мы рассмотрим в отдельной теме.

MariaDB

MariaDB — синхронизирована с кодовой базой MySQL и полностью с ней совместима, т.е. может выступать в качестве прозрачной замены MySQL, обладая при этом рядом расширенных функций, включая оптимизации производительности и поставляясь с набором дополнительных движков хранилищ, подробно данную БД мы рассматривать не будем поскольку ничего особо интересного здесь нет.

Установка MySQL сервера

Мы будем работать с Percona Server, для установки выполнятся следующие команды:

Устанавливаем репозиторий

yum install -y http://www.percona.com/downloads/percona-release/redhat/0.1-6/percona-release-0.1-6.noarch.rpm

И устанавливаем сам сервер, который через зависимости также ставит и клиент

yum install -y Percona-Server-server-57

Добавляем сервер в автозагрузку и запускаем

systemctl enable mysqld; systemctl start mysql
 Во время первого запуска СУБД генерируется временный root пароль, что бы его достать достаточно грепнуть лог mysqld

grep "temporary password" /var/log/mysqld.log

Теперь запускаем утилиту которая называется mysql_secure_installation:
mysql_secure_installation

Она попросит ввести временный root пароль и попросит сразу установить новый, устанавливаем новый пароль, затем будет запрос на удаление анонимных пользователей, также отвечаем да, далее запрос на запрет подключение к БД удаленно под пользователем root, также отвечаем Да, отвечаем да на удаление тестовых БД и перезагрузку таблицы привилегий.

На этом установка и базовые настройки безопасности завершены.

Переходим к конфигурации Percona сервера, основной конфигурационный файл находится по адрес /etc/percona-server.conf.d/mysqld.cnf, через него мы и будем производить конфигурацию сервера. 

Теперь давай разберем основные настройки MySQL сервера которые вы чаще всего будете использовать:

bind-address - указывается адрес по которому будет слушать MySQL сервер, если сервер и приложение находятся на одном сервере рекомендую установить значение в localhost, если у вас есть локальная сеть рекомендую биндить сервер на локальный адрес, ну а если есть только внешний адрес и нужен доступ по нему открывайте, но не забывайте ограничить доступ к mysql серверу через iptables списком разрешенных адресов, а также при создании пользователей указывать разрешение на подключение только с необходимых адресов и никогда со всех сразу.

max_connections
Сколько разрешить одновременных соединений?
Что бы понять сколько все же необходимо следите за значением max_used_connections которое вы можете увидеть с помощью команды show status выполнению в консоли mysql.

thread_cache
- Кэш для предотвращения создания избыточных потоков
- Автоматически устанавливается в MySQL 5.6
- В некоторых случаях 50-100 оптимальное значение. Следите за значением threads_created.

table_cache/table_open_cache
Кэш открытых экземпляров (инстансов) таблиц.
Единичная таблица может иметь несколько записей.
Следите за opened_tables, начните с 4096. MySQL будет использовать их только по мере необходимости, в любом случае.

table_open_cache_instances
Целесообразно повышать это значение если есть много конкурентных запросов к кешу таблиц.

open_files_limit
Таблицы MyISAM требуют до 2-х обработчиков файлов, каждое соединение это тоже обработчик файлов. Для большинства систем безопасно устанавливать значение "65535".

table_definition_cache
Кеширование определений таблиц (CREATE TABLE)
Только одна запись на таблицу.
Следите за Opened_table_definitions.
Устанавливайте значение числа имеющихся таблиц + 10%, только до того как число не перевалило за 50K+ таблиц

max_allowed_packet
- Ограничивает максимальный размер запроса
- Ограничивает размер переменной внутренней строки
- 16MB хорошее значение
Увеличивать стоит когда получаете ошибку “Пакет слишком большой или подобные”

max_connect_errors
- Может вызвать ошибки “Host Blocked”
- Особенно полезно при работе на слабой неустойчивой сети.
- Значение около 1000000 должно подойти в большинстве случаев.

skip_name_resolve
- Исключает распознавание DNS имен при подключениях. Быстрее и надежнее.
- Не используйте хостнеймы при назначении GRANT привилегий.

query_cache_size
- Включайте кеш запросов если хотите получить значительные улучшения, но только если предварительно проверили его эффективность.
- Часто вызывает задержки и конфликты.
- Не ставьте значения выше 512Мб.

sort_buffer_size
- Буфер в памяти, используется для сортировок
- Следите за sort_merge_passes
- Рассмотрите возможность создания сессии для больших запросов
- В MySQL 5.6 значение по умолчанию снижено до 256K 
– Большие значения повредят производительности малых запросов

join_buffer_size
- Улучшает производительность "объединений" (Joins) без индексов.
– Лучше избавиться от таких "объединений"!
- 8MB может быть разумным значением.

read_rnd_buffer_size
- Буфер для чтения строк в отсортированном виде
- Значениы около 16M часто имеют смысл.
- Также используется как буфер для MRR в версии 5.6
- Не путайте с read_buffer_size!

default_storage_engine
- Использует этот движок для таблиц, если не задан
- Также проверяйте default-tmp-storage-engine

tmpdir
- Обозначает путь к временной директории
- Обычно Tmpfs хороший выбор, но только до тех пор пока не появляется необходимость увеличить размер временного хранилища.
- tmpdir=/dev/shm

tmp_table_size / max_heap_table_size
- Обычно устанавливает одно и то же значение (основанное на рабочей нагрузке)
- Переменная статуса сreated_tmp_disk_tables 
- Будьте осторожны, поля BLOB/TEXT могут повлечь создание на диске таблиц любого размера.

old_passwords
Не должно быть включено. Может привести к использованию не безопасных (скомпрометированных) паролей.

log_bin
- Включается для репликации и для точки восстановления
- Выставляйте как “mysql-bin” чтобы избежать именования по умолчанию.

sync_binlog
- Помещайте Binlog на долговечное и отказоустойчивое хранилище. Выставляйте значение 1 если у вас RAID с батарейкой или Flash.
- Может вызвать значительное снижение производительности на медленных дисках.

expire_log_days
- Очистка старых бинарных логов после заданного количества дней.
- Зависит от размеры БД

Логирование

slow_query_log
– Включает лог медленных запросов. Часто бывает что причиной перегрузки MySQL сервера бывают тяжелые или медленные запросы, включение данного лога помогает их отловить.

long_query_time
– Особенно в связке с long_query_time выставляйте в 0 периодически, чтобы получить образец тяжелого запроса.

log_slow_verbosity=full
– Выдает намного больше данных о запросах с Percona Server

userstat=1
- Выдает продвинутую статистику о использовании таблиц и индексов в Percona Server и MariaDB

InnoDB

Настройки памяти

innodb_buffer_pool_size
- Наиболее важное значение. Обычно занимает до 80%+ от общей памяти сервера.

innodb_buffer_pool_instances
- Уменьшает конфликты блокировок. В MySQL 5.6 по умолчанию - 8

innodb_log_buffer_size
- Буфер для логов. От 4MB до 128MB обычно хорошие значения.
- Не только уменьшает количество операций записи, но и помогает уменьшить конфликты.

innodb_change_buffer_max_size
- Контролирует размер буфера вставок. По умолчанию ¼ буферного пула. Меньшие значения хороши для SSD

Ввод/вывод, основные опции

innodb_flush_log_at_trx_commit
- Контролирует как часто и как сбрасывать буфер транзакций на диск
- 1=сбрасывать и сихронизировать; 2=не сбрасывать буфер на диск, только в кэш ОС; 0=не сбрасывать

innodb_flush_method
- Контролирует как Innodb выполняет ввод/вывод
- O_DIRECT хорошо для большинства случаев

innodb_io_capacity
- Контролирует допущение Innodb по части производительности ввода / вывода. Увеличивайте для быстрых дисков по мере возможности. По умолчанию значение "200", но этого может оказать мало в ряде случаев.

Прочие параметры

innodb_log_file_size
- Больше лог = лучше производительность, но дольше восстановление.

innodb_log_files_in_group
- По умолчанию 2 и этого достаточно.

innodb_file_per_table
- Храните каждую таблицу Innodb в отдельном файле. По умолчанию начиная с MySQL 5.6

innodb_lock_wait_timeout
- Сколько ждать освобождения блокировки строки.

innodb_old_blocks_time
- Помогает сделать устойчивым сканирование буферного пула.
- Имеет смысл выставлять значение - 1000
- По умолчанию в MySQL 5.6

innodb_file_format
- Какой формат файла будет использовать Innodb
- “Antelope” используется по умолчанию
- “Barracuda” позволяет использовать новые фичи, такие как компрессия.

innodb_stats_on_metadata
- Обновление статистики при обращении к метаданным
- Обычно лучше отключать особенно при высоких рабочих нагрузках.
- Отключено по умолчанию в MySQL 5.6

Важно знать

Некоторые опции, которые не стоит увеличивать

Если вдруг память на сервере увеличилась в 8 раз, не стоит бросаться увеличивать все значения всех переменных конфигурации в 8 раз.

Допустим было 16GB памяти, стало 128GB. При этом увеличение sort_buffer_size с 4MB до 32MB - плохая идея. Или еще хуже выставить sort_buffer_size=16G. Так делать нельзя! Величина sort_buffer_size определяет выделение буфера сортировки на каждое соединение.

На слайде вы можете видеть как считаются размеры буферов и максимально возможное потребление памяти

Избегайте типичных ошибок

Дублирование опций - сервер будет присваивать то значение опции которое считает последним.
Использование неверной секции для опции.
[mysqld] - секция для сервера, [mysql] - секция для клиента

О конфигах

Синхронизируйте конфигурации на серверах. Отсутствие синхронизации часто ведет к ошибкам и недоразумениям.

Ведите записи о всех изменениях. Очень хорошо если вы держите конфиги в системе контроля версий или модифицируете их через систему управления конфигурациями.
Документируйте изменения.

Исключайте свопинг MySQL.

Выделяйте для MySQL столько памяти сколько можете.
Свопинг очень плохо сказывается на производительности всей системы в целом.
Следите за свопингом.
Начинайте с малых значений буферов и увеличивайте их постепенно если есть много свободной памяти.

Применение настроек без даунтайма

Немногие знают, но на самом деле в MySQL большинство параметров можно изменить без перезагрузки сервера, делается это достаточно просто, пример на слайде.

Так мы включаем сбор медленных запросов без перезагрузки сервера MySQL тоже самое можно сделать со многими параметрами MySQL, но естественно не со всеми. Для того что бы наверняка определить является ли параметр динамическим или нет рекомендую обратиться к официальной документации MySQL

Анализ запросов к серверу баз данных

MySQL EXPLAIN - функция используемая для анализа медленных запросов в MySQL и определения запросов, которые нужно оптимизировать.

Синтаксис команды очень прост - в консоли сервера баз данных вводится EXPLAIN, затем запрос к MySQL

На практике EXPLAIN обычно передаются для анализа запросы, выполняющиеся непосредственно в настоящее время. Их можно посмотреть с помощью SHOW PROCESSLIST; или запросы из лога медленных запросов

Возьмем как пример запрос EXPLAIN указанный на слайде и его вывод:

Особый интерес при оптимизации представляют значения следующих полей:
possible_keys - возможные ключи, здесь выводятся созданные MySQL индексы, которые можно использовать 
key - использованные при запросе индексы
rows - количество записей, которые MySQL пришлось проверить чтобы вернуть результат; при оптимизации следует стремиться к минимальному значению 
Extra - словесное описание того, что используется в запросе
Другие поля:
id - идентификатор SELECT - важно в случае если в одном запросе их несколько
select_type - тип SELECT-а; для простых запросов это SIMPLE, для те в которых используются UNION операторы и вложенные запросы выводятся другие значения
table - таблица, которая задействуется
type - здесь для запросов, не использующих индексы, можно увидеть значение all, это самый плохой вариант говорящий о том, что MySQL приходится обойти все значения чтобы вывести результат.
key_len - важно при составных индексах для того чтобы понять используется ли он весь или только какая-то часть
ref - в качестве значения выводятся те поля, которые были использованы оптимизатором запросов вместе с ключем
 
В примере индексов нет и серверу баз данных пришлось перебрать 7 значений чтобы вернуть результат.

Создадим простой индекс и проверим изменится ли вывод

Сейчас используется индекс PRICE и MySQL выдал результат проверив только одно поле.
 
EXPLAIN особенно эффективен при тонкой настройке и оптимизации сложных запросов к базе в больших приложениях.  EXPLAIN выводит ту информацию, которая используется оптимизатором, которые является одним из основных механизмов  MySQL.

Фактически запрос, который мы анализировали возвращает пустое значение. Но скорость обработки улучшилась в несколько раз, при больших нагрузках это может иметь значение.

На этом данную тему мы завершаем и переходим к теме настройки репликации MySQL в режиме Master-Slave.

3. MySQL. Настройка репликации Master-Slave c минимальным простоем. 

Прежде чем я расскажу о настройке репликации давайте простыми словами разберем что такое репликация и как она работает.

Репликация — одна из техник масштабирования баз данных. Состоит эта техника в том, что данные с одного сервера базы данных постоянно копируются (реплицируются) на один или несколько других (называемые репликами). Для приложения появляется возможность использовать не один сервер для обработки всех запросов, а несколько. Таким образом появляется возможность распределить нагрузку с одного сервера на несколько.

Существует два основных подхода при работе с репликацией данных:

* Репликация Master-Slave;
* Репликация Master-Master.

Master-Slave репликация

В этом подходе выделяется один основной сервер базы данных, который называется Мастером. На нем происходят все изменения в данных (любые запросы MySQL INSERT/UPDATE/DELETE). Слейв сервер постоянно копирует все изменения с Мастера. С приложения на Слейв сервер отправляются запросы чтения данных (запросы SELECT). Таким образом Мастер сервер отвечает за изменения данных, а Слейв за чтение.

Преимущество этого типа репликации в том, что Вы можете использовать более одного Слейва. Обычно следует использовать не более 20 Слейв серверов при работе с одним Мастером.

Асинхронность репликации означает, что данные на Слейве могут появится с небольшой задержкой. Поэтому, в последовательных операциях необходимо использовать чтение с Мастера, чтобы получить актуальные данные

При выходе из строя Слейва, достаточно просто переключить все приложение на работу с Мастером. После этого восстановить репликацию на Слейве и снова его запустить.

Если выходит из строя Мастер, нужно переключить все операции (и чтения и записи) на Слейв. Таким образом он станет новым Мастером. После восстановления старого Мастера, настроить на нем реплику, и он станет новым Слейвом.

Намного чаще репликацию Master-Slave используют не для масштабирования, а для резервирования. В этом случае, Мастер сервер обрабатывает все запросы от приложения. Слейв сервер работает в пассивном режиме. Но в случае выхода из строя Мастера, все операции переключаются на Слейв.

Master-Master репликация

В этой схеме, любой из серверов может использоваться как для чтения так и для записи.

При использовании такого типа репликации достаточно выбирать случайное соединение из доступных Мастеров.

Вероятные поломки делают Master-Master репликацию непривлекательной. Выход из строя одного из серверов практически всегда приводит к потере каких-то данных. Последующее восстановление также сильно затрудняется необходимостью ручного анализа данных, которые успели либо не успели скопироваться.

Используйте Master-Master репликацию только в крайнем случае. Вместо нее лучше пользоваться техникой "ручной" репликации

Следует помнить, что репликация — это не технология, а методика. Встроенные механизмы репликации могут принести ненужные усложнения либо не иметь какой-то нужной функции. Некоторые технологии вообще не имеют встроенной репликации.

В таких случаях, следует использовать самостоятельную реализацию репликации. В самом простом случае, приложение будет дублировать все запросы сразу на несколько серверов базы данных

При записи данных, все запросы будут отправляться на несколько серверов. Зато операции чтения можно будет отправлять на любой сервер. Нагрузка при этом будет распределяться по всем доступным серверам

Это позволит использовать преимущества репликации даже если сама технология ее не поддерживает.

При поломке одного из серверов в такой схеме необходимо сделать следующее:

* Исключить сервер из списка используемых.
* Настроить репликацию Master-Slave на новом сервере, используя один из рабочих серверов в качестве Мастера.
* Когда все данные репликации будут синхронизированы, включить сервер обратно в список используемых и остановить репликацию.

Репликация используется в большей мере для резервирования баз данных и в меньшей для масштабирования. Master-Slave репликация удобна для распределения запросов чтения по нескольким серверам. Подход ручной репликации позволит использовать преимущества репликации для технологий, которые ее не поддерживают. Зачастую репликация используется вместе с шардингом при решении вопросов масштабирования.

Переходим непосредственно к настройке репликации с помощью Xtrabackup

Перед настройкой репликации необходимо проверить версии mysql на master и slave.  Это важно версии должны быть идентичными.

Для настройки репликации нам потребуется утилита innobackupex из пакета percona-xtrabackup

innobackupex - скрипт для расширения функционала xtrabackup, возможности которого ограничены только дампом баз InnoDB, innobackupex позволяет делать полный дамп всех баз в том числе и MyISAM.

Кратко об основных опциях:

--user
Пользователь MySQL который будет использоваться для подключения к MySQL, соотвественно "--password" пароль для него.

--apply-log
Подготавливает бекап применяя к нему транзакционный лог "xtrabackup_logfile", 
также создает новые транзакционные логи.

--copy-back
Копирует файлы бекапа в папку назначения.

--databases=LIST
Список баз для резервирования. Базы указываются через пробел, также можно указывать таблицы:
"databasename1[.table_name1] databasename2[.table_name2] . . ."

--defaults-file=[MY.CNF]
Указывает файл с которого будут считываться опции MySQL.

--rsync
Позволяет использовать rsync для копирования файлов таблиц MyISAM, 
уменьшает время блокировок таблиц MyISAM "FLUSH TABLES WITH READ LOCK".

--incremental
Создает инкрементальный бекап.
Требуется указать --incremental-basedir директорию содержащую полный бекап.

--parallel=NUMBER-OF-THREADS
Позволяет распараллелить процесс бекапа в несколько потоков.
Актуально при innodb_file_per_table=1.

--slave-info
Актуально для бекапа на slave-сервере. Выводит позицию бинарного лога и имя мастер-сервера.
Записывает информацию в файл "xtrabackup_slave_info" в виде команды "CHANGE MASTER". 
Полезно для подключения нового слейва.

После установки innobackupex нужно подготовить мастер-сервер, включив бинарные логи и присвоив server-id

Создадим каталог для бинлогов и добавим необходимые параметры в конфиг MySQL и перезапустим сервер. Обратите внимание, что логи будут храниться 7 дней. Если дискового пространства не так много, то необходимо выставить меньшее количество дней.

mkdir -p /var/log/mysql
chown mysql:mysql /var/log/mysql

[mysqld]
server-id = 1
log_bin = /var/log/mysql (на слайде ошибка)
binlog_format = MIXED
expire_logs_days = 7
max_binlog_size = 1G

Делаем бекап и применяем лог

rm -rf /var/backups/mysql/xtra
mkdir -p /var/backups/mysql/xtra
innobackupex --user=root --password=`cat /root/.mysql` --rsync /var/backups/mysql/xtra/
TIMESTAMP=`/bin/ls -1 /var/backups/mysql/xtra/ | sort -r | head -1`
innobackupex --user=root --password=`cat /root/.mysql` --apply-log /var/backups/mysql/xtra/$TIMESTAMP

Скопируем бекап на слейв-сервер и сразу удалим бэкап с мастера.

Master # rsync -avprP -e ssh /var/backups/mysql/xtra/$TIMESTAMP/ Slave:/var/lib/mysql/
Master # rm -rf /var/backups/mysql/xtra

В случае переподнятия реплики старый каталог /var/lib/mysql нужно переименовать или удалить.

Выставим корректные права на файлы БД

Slave # chown -R mysql:mysql /var/lib/mysql/
Slave # chmod +x /var/lib/mysql

Сконфигурируем мастер-сервер MySQL

Создадим пользователя для репликации

Master # mysql> GRANT REPLICATION SLAVE ON *.*  TO 'replica'@'%' IDENTIFIED BY '$slavepass';

Проверим подключение к мастеру

Slave # mysql --host=Master --user=replica --password=$slavepass

Сохраним пароль на слейве, чтобы потом не искать его

echo "replica:$slavepass" > /root/.mysql-slave

Сконфигурируем слейв-сервер MySQL

Копируем конфигурацию MySQL с мастера на слейв

Slave # scp root@Master:/etc/my.cnf /etc/my.cnf

Добавляем в секцию [mysqld] конфига MySQL опцию защиты слейва от записи:

read_only=on

Поправим id сервера в конфиге

server-id=2

Запустим репликацию

Позицию бинарного лога можно посмотреть командой указаной на слайде, она нужна что бы указать слейву с какого места начать синхронизацию данных

Slave # cat /var/lib/mysql/xtrabackup_binlog_info
mysql-bin.000010        28973559

Зададим параметры мастер сервера

Slave # mysql> STOP SLAVE;
Slave # mysql> RESET SLAVE;
Slave # mysql> CHANGE MASTER TO MASTER_HOST='$masterip', MASTER_USER='replica', MASTER_PASSWORD='$slavepass', MASTER_LOG_FILE='mysql-bin.000010', MASTER_LOG_POS=28973559;

И запустим репликацию

Slave # mysql> START SLAVE;

Проверяем статус

Slave # mysql> SHOW SLAVE STATUS \G
         ...
         Slave_IO_Running: Yes
         Slave_SQL_Running: Yes
         ...
         Seconds_Behind_Master: 13
         ...

Если никаких ошибок нет на этом настройку репликации можно считать завершенной

4. PostgreSQL. Установка, основы архитектуры, настройка

Переходим к СУБД PostgreSQL.

PostgreSQL также является одной из самых популярных баз данных. За более чем 20-летнюю историю развития на прочном фундаменте, заложенном академической разработкой, PostgreSQL выросла в полноценную СУБД уровня предприятия и составляет реальную альтернативу коммерческим базам данных.

Надежность и устойчивость 

Вопросы обеспечения надежности особенно важны в приложениях уровня предприятия для работы с критически важными данными. С этой целью PostgreSQL позволяет настраивать горячее резервирование, восстановление на заданный момент времени в прошлом, различные виды репликации (синхронную, асинхронную, каскадную). 

Безопасность 

PostgreSQL позволяет работать по защищенному SSL-соединению и предоставляет большое количество методов аутентификации, включая аутентификацию по паролю, клиентским сертификатам, а также с помощью внешних сервисов (LDAP, RADIUS, PAM, Kerberos). 

При управлении пользователями и доступом к объектам БД предоставляются следующие возможности: 

* Создание и управление пользователями и групповыми ролями; 
* Разграничение доступа к объектам базы данных на уровне как отдельных пользователей, так и групп; 
* Детальное управление доступом на уровне отдельных столбцов и строк; 
* Поддержка SELinux через встроенную функциональность

Поддержка транзакционности  
PostgreSQL обеспечивает полную поддержку свойств ACID и обеспечивает эффективную изоляцию транзакций. Для этого в PostgreSQL используется механизм многоверсионного управления одновременным доступом. Он позволяет обходиться без блокировок во всех случаях, кроме одновременного изменения одной и той же строки данных в нескольких процессах. При этом читающие транзакции никогда не блокируют пишущие транзакции, а пишущие — читающих. Это справедливо и для самого строгого уровня изоляции serializable, который, обеспечивает полное отсутствие аномалий сериализации и гарантирует, что при одновременном выполнении транзакций результат будет таким же, как и при последовательном выполнении.  
Масштабируемость и производительность 

PostgreSQL эффективно использует современную архитектуру многоядерных процессоров — его производительность растет практически линейно с увеличением количества ядер. 

Начиная с версии 9.6, PostgreSQL научился параллельно читать данные, соединять их и выполнять агрегации, что еще больше повышает возможности использования аппаратных средств для ускорения операций. 

Планировщик запросов 

В PostgreSQL используется планировщик запросов, основанный на стоимости. Используя собираемую статистику и учитывая в своих математических моделях как дисковые операции, так и время работы процессора, планировщик позволяет оптимизировать самые сложные запросы. В его распоряжении находятся все методы доступа к данным и способы выполнения соединений, характерные для передовых коммерческих СУБД. 

Расширяемость 

Расширяемость — одно из фундаментальных преимуществ системы, лежащее в основе архитектуры PostgreSQL. Пользователи могут самостоятельно, не меняя базовый код системы, добавлять: 

* Типы данных; 
* Функции и операторы для работы с новыми типами; 
* Индексные методы доступа; 
* Языки серверного программирования; 
* Подключения к внешним источникам; 
* Загружаемые расширения.  
Полноценная поддержка расширений позволяет реализовать функционал любой сложности, не внося изменений в ядро PostgreSQL и допуская подключение по мере необходимости. Например, именно в виде расширений построены такие сложные системы, как: 

* CitusDB — возможность распределения данных по разным экземплярам PostgreSQL (шардинг) и массивно-параллельного выполнения запросов; 
* PostGIS — система обработки геоинформационных данных.  
Только стандартный комплект, входящий в сборку PostgreSQL 9.6, содержит более полусотни расширений, доказавших свою надежность и полезность.  
Независимость 

PostgreSQL не принадлежит ни одной компании и развивается международным сообществом, в том числе и российскими разработчиками. Это означает, что системы, использующие PostgreSQL, не зависят от конкретного вендора, тем самым  в любой ситуации сохраняя вложенные в них инвестиции. 

Установка PostgreSQL

Репозиторий

Установка производится из официального репозитория, добавляем репозиторий

yum install -y https://download.postgresql.org/pub/repos/yum/9.6/redhat/rhel-7-x86_64/pgdg-centos96-9.6-3.noarch.rpm

Устанавливаем PostgreSQL

yum install -y postgresql96 postgresql96-server postgresql96-contrib 
Инициализируем базу

--lc-message=en_US.UTF-8, необходима именно данная кодировка, Postgres будет выводить сообщения в лог на английском языке, чтобы анализаторы логов, могли потом их прочитать

sudo -u postgres /usr/pgsql-9.6/bin/initdb -E utf8 --locale=en_US.UTF-8 --lc-message=en_US.UTF-8 --lc-collate=en_US.UTF-8 -D /var/lib/pgsql/9.6/data/

Первоначальная настройка

Удалённый доступ

Что бы открыть удаленный доступ к postgresql, в конфиге указываем listen как указано на слайде, так мы откроем доступ всем, можно указать список IP с которых разрешен доступ через запятую

Если указан доступ для всех добавляем разрешения для нужных IP в iptables остальных блокируем

Редактируем конфиги pgsql

Помимо основного конфига нам потребуются еще два файла конфигурации это:
pg_hba.conf	файл аутентификации	для применения изменений которого достаточно выполнить reload
И pg_ident.conf	файл сопоставления имён пользователей	для применения изменений которого также достаточно выполнить reload

pg_hba.conf

local   all             postgres        ident                   map=supervisor
local   all             all                                     md5
host    all             all             127.0.0.1/32            md5
host    all             all             0.0.0.0/0               md5

pg_ident.conf

supervisor      postgres                postgres
supervisor      root                    postgres

Приводим содержимое файла pg_hba.conf к состоянию указанному на слайде, остальное оттуда можно удалить
Тоже самое делаем с pg_ident.conf
  И добавляем сервис в автозагрузку и запускаем

Теперь у нас есть работающий PostgreSQL.

Далее я приведу основные параметры, на которые стоит обращать внимание для более тонкой настройки Postgres.

superuser_reserved_connections - количество подключений зарезервированное для супер пользователя. Стоит выставлять не меньше 5.
Определяет количество "слотов" подключений, которые PostgreSQL будет резервировать для суперпользователей. При этом всего одновременно активными могут быть максимум подключений установленных в параметре max_connections. Когда число активных одновременных подключений больше или равно max_connections минус superuser_reserved_connections, принимаются только подключения суперпользователей, а все другие подключения, в том числе подключения для репликации, запрещаются.

shared_buffers
Задаёт объём памяти, который будет использовать сервер баз данных для буферов в разделяемой памяти. По умолчанию это обычно 128 мегабайт (128MB). Начать стоит с 25% от общего объема оперативной памяти. А дальше, подобрать имперечиским путем анализируя занятость буфера.

temp_buffers
Задаёт максимальное число временных буферов для каждого сеанса, По умолчанию объём временных буферов составляет восемь мегабайт (1024 буфера). Этот параметр можно изменить в отдельном сеансе, но только до первого обращения к временным таблицам; после этого изменить его значение для текущего сеанса не удастся.
Сеанс выделяет временные буферы по мере необходимости до достижения предела, заданного параметром temp_buffers. Если сеанс не задействует временные буферы, то для него хранятся только дескрипторы буферов, которые занимают около 64 байтов (в количестве temp_buffers).

work_mem
Задаёт объём памяти, который будет использоваться для внутренних операций сортировки и хеш-таблиц, прежде чем будут задействованы временные файлы на диске. Значение по умолчанию — четыре мегабайта (4MB). В сложных запросах одновременно могут выполняться несколько операций сортировки или хеширования, так что этот объём памяти будет доступен для каждой операции. Кроме того, такие операции могут выполняться одновременно в разных сеансах. Таким образом, общий объём памяти может многократно превосходить значение work_mem; это следует учитывать, выбирая подходящее значение. Операции сортировки используются для ORDER BY, DISTINCT и соединений слиянием. Хеш-таблицы используются при соединениях и агрегировании по хешу, а также обработке подзапросов IN с применением хеша.
В идеале должен быть не меньше объема самой большой таблицы.

maintenance_work_mem
Задаёт максимальный объём памяти для операций обслуживания БД, в частности VACUUM, CREATE INDEX и ALTER TABLE ADD FOREIGN KEY и так далее
Неплохо бы устанавливать его значение от 50 до 75% размера вашей самой большой таблицы или индекса

effective_io_concurrency
Задаёт допустимое число параллельных операций ввода/вывода, которое говорит Postgres о том, сколько операций ввода/вывода могут быть выполнены одновременно. Чем больше это число, тем больше операций ввода/вывода будет пытаться выполнить параллельно Postgres в отдельном сеансе. Допустимые значения лежат в интервале от 1 до 1000, а нулевое значение отключает асинхронные запросы ввода/вывода.

max_worker_processes
Задаёт максимальное число фоновых процессов, которое можно запустить в текущей операционной системе. Этот параметр можно задать только при запуске сервера.
Для сервера, работающего в режиме резерва, значение этого параметра должно быть больше или равно значению на главном. В противном случае на резервном сервере не будут разрешены запросы. Выставлять значение не меньше количества ядер.

WAL

Журнал Опережающей Записи (WAL) — это стандартный метод обеспечения целостности данных. Детальное описание можно найти в большинстве (если не всех) книг по обработке транзакций. Вкратце, основная идея WAL состоит в том, что изменения в файлах с данными (где находятся таблицы и индексы) должны записываться только после того, как эти изменения были занесены в журнал, т.е. после того как записи журнала, описывающие данные изменения, будут сохранены на постоянное устройство хранения. Если следовать этой процедуре, то записывать страницы данных на диск после каждого подтверждения транзакции, нет необходимости, потому что мы знаем, что если случится крах, то у нас будет возможность восстановить базу данных с помощью журнала: любые изменения, которые не были применены к страницам с данными, могут быть воссозданы из записей журнала. (Это называется восстановлением с помощью наката, также известным как REDO.)

max_wal_size
Максимальный размер, до которого может вырастать WAL между автоматическими контрольными точками в WAL. Это мягкий предел; размер WAL может превышать max_wal_size при особых обстоятельствах, например, при высокой нагрузке, сбое в archive_command или при большом значении wal_keep_segments. 
Его значение задается исходя из интенсивности запросов в БД. Если значение недостаточно, это будет отображено в логах.

checkpoint_timeout
Максимальное время между автоматическими контрольными точками в WAL (в секундах). Допускаются значения от 30 секунд до одного часа. Значение по умолчанию — пять минут (5min). Увеличение этого параметра может привести к увеличению времени, которое потребуется для восстановления после сбоя.

5. PostgreSQL. Репликация, бэкапы + Практика

Коротко о главном

Когда вы изменяете данные в базе, все изменения пишутся во Write-Ahead Log, или WAL. После записи в WAL СУБД делает системный вызов fsync, благодаря чему данные попадают сразу на диск, а не висят в где-то в кэше файловой системы. Таким образом, если взять и обесточить сервер, при следующей загрузке СУБД прочитает последние записи из WAL и применит к базе данных соответствующие изменения.

Потоковая репликация (streaming replication) в сущности является передачей записей из WAL от мастера к репликам. Писать при этом можно только в мастер, но читать можно как с мастера, так и с реплик. Если с реплики разрешено читать, она называется hot standby, иначе — warm standby. Поскольку во многих приложениях 90% запросов являются запросами на чтение, репликация позволяет масштабировать базу данных горизонтально. Потоковая репликация бывает двух видов — синхронная и асинхронная.

При асинхронной репликации запрос тут же выполняется на мастере, а соответствующие данные из WAL доезжают до реплик отдельно, в фоне. Недостаток асинхронной репликации заключается в том, что при внезапном падении мастера (например, из-за сгоревшего диска) часть данных будет потеряна, так как они не успели доехать до реплик.

При использовании синхронной репликации данные сначала записываются в WAL как минимум одной реплики, после чего транзакция выполняется уже на мастере. Запросы на запись выполняются медленнее в результате возникающих сетевых задержек (которые, однако, внутри одного ДЦ обычно меньше типичного времени планирования запроса). Кроме того, чтобы запросы на запись не встали колом в результате падения одной из реплик, при использовании синхронной репликации рекомендуется использовать по крайней мере две реплики. Зато потерять данные становится намного сложнее.

Заметьте, что синхронная репликация не предотвращает возможности считать с реплики старые данные, так как потоковая репликация — она только про передачу WAL, а не то, что видно в базе с точки зрения пользователя. По крайней мере, так синхронная репликация работает конкретно в PostgreSQL.

В контексте репликации нельзя также не отметить еще один интересный термин. Если одна из реплик в свою очередь является мастером для другой реплики, такую конфигурацию называют каскадной репликацией.

Помимо потоковой репликации в последнее время выделяют еще и так называемую логическую репликацию (logical replication). Реализаций логической репликации в PostgreSQL существует несколько, например, slony и pglogical. Пожалуй, наиболее существенное отличие логической репликации от потоковой заключается в возможности реплицировать часть баз данных и таблиц на одни реплики, а часть — на другие. Платить за это приходится скоростью. 

В PostgreSQL 10 добавили логическую репликацию, теперь она есть из коробки.

Интересный факт! Потоковая репликация в PostgreSQL не работает между разными версиями PostgreSQL, а также если на серверах используется разная архитектура CPU. В частности, это означает, что обновить PostgreSQL до следующей версии при использовании потоковой репликации без даунтайма нельзя. Отсюда еще больший интерес к логический репликации, лишенной этого недостатка.

Переходим к настройке репликации.

Выставляем ведение журнала таким образом, чтобы Slave мог использоваться для чтения. Уровень replica также подойдет для архивации WAL.
До версии 9.6 уровень для реплицирования назывался hot_standby, а для архивации - archive

Устанавливаем Максимальное количество подключаемых Slave серверов max_wal_senders

Параметр wal_keep_segments определяет минимальное количество сегментов лога, которые будут храниться в pg_xlog, и будут получены слейвом для репликации. Каждый сегмент по умолчанию равен 16 мегабайт. При отставании Slave от Master'а больше чем на количество сегментов, указанных в wal_keep_segments, мастер удалит нужные сегменты WAL и репликация будет прервана. Следует исходить из того, что места должно быть достаточно для хранения данных по формуле 16MB (сегмент) умноженных на значение wal_keep_segments. Если вдруг у вас большая нагрузка на запись в базу - возможно это значение нужно будет увеличить, чтобы всё успевало доезжать до реплики.

На случай "ядерной войны" дублируем журнал в отдельное место (лучше чистить по крону эту локацию, удаляя всё, чему больше суток). Архивировать журнал не обязательно в случае если вообще нет такой необходимости, или если выставлен корректный wal_keep_segments и если реплика спокойно успевает обрабатывать тот объем WAL что ему передается.

wal_level = replica
max_wal_senders = 2
wal_keep_segments = 32
archive_mode = on
archive_command = 'cp %p /var/lib/pgsql/9.6/data/archive/%f'

Добавляем в pg_hba.conf параметр разрешающий подключение со слейва

УКАЗАТЬ IP СЛЕЙВ СЕРВЕРА

host    replication     syncuser        192.168.0.2/32          trust

Создаём каталог на Master'е под архивы

mkdir -p /var/lib/pgsql/9.6/data/archive/
chown -R postgres:postgres /var/lib/pgsql/9.6/data/archive
chmod 700 /var/lib/pgsql/9.6/data/archive/

Перезапускаем Postgres

И добавляем пользователя репликации syncuser на Master'е

sudo -u postgres psql -c "CREATE ROLE syncuser REPLICATION LOGIN ENCRYPTED PASSWORD 'password';" 

Настраиваем слейв

В случае если на Slave выполняется установка не "с нуля" - лучше сделать бекап каталога PostgreSQL data, после чего очистить её содержимое. Если этого не сделать - синхронизацию выполнить не получится, pg_basebackup будет отказываться её делать с ошибкой "directory  exists but is not empty".

Запускаем базовый бекап через пользователя репликации

sudo -u postgres /usr/pgsql-9.6/bin/pg_basebackup -h<IP мастера> -U syncuser -D /var/lib/pgsql/9.6/data -v -P

Вносим запись в pg_hba.conf

НЕОБХОДИМО УКАЗАТЬ IP МАСТЕР СЕРВЕРА

host replication syncuser 192.168.0.1/32 trust

Вносим параметры в postgresql.conf. 

hot_standby = on
max_standby_streaming_delay = 3600s
max_standby_archive_delay = 3600s

Создаём файл recovery.conf (в случае переключения в режим мастера по триггеру он переименуется), с содержимым

standby_mode = 'on'
primary_conninfo = 'host=192.168.0.1 port=5432 user=syncuser'
trigger_file = '/var/lib/pgsql/9.6/data/trigger'
restore_command = 'cp /var/lib/pgsql/9.6/data/archive/%f "%p"'

Строку с restore_command в recovery.conf нужно убрать, если архивация WAL не планируется

trigger_file, по дефолту его быть не должно. Он нужен для того, чтобы в случае факапа вы могли, создав этот файл, остановить процесс репликации и сделать Slave доступным на запись.

Даем права на recovery.conf

chown postgres:postgres recovery.conf

Теперь Slave нужно перезапустить

systemctl restart postgresql-9.6

После запуска на слейве должен появится процесс startup, это говорит нам о том что началась синхронизация данных и текущую позицию синхронизации. (ps aux | grep postgres)

После завершения синхронизации данных мы увидим что появился процесс receiver (ps aux | grep receiver)

На этом настройку репликации PostgreSQL можно считать завершенной

Переходим к Redis

6. Redis. Установка и основы архитектуры

Установка redis тривиальна и выполняется одной командой, не будем на этом зацикливаться и перейдем сразу к архитектуре

Redis – быстрое хранилище в памяти с открытым исходным кодом для структур данных «ключ-значение». Redis поставляется с набором разнообразных структур данных в памяти, что упрощает создание различных специальных приложений. Самые распространенные примеры использования Redis включают кэширование, управление сессиями, системы «издатель-подписчик» и таблицы лидеров. Это самое популярное на текущий момент хранилище пар «ключ-значение». Оно обладает лицензией BSD, написано на оптимизированном коде C и поддерживает несколько языков разработки. Название Redis является акронимом от REmote DIctionary Server.

Благодаря высокой скорости и простоте Redis часто используется для мобильных и интернет-приложений, игр, рекламных платформ, «Интернета вещей», т. е. в тех случаях, когда необходима максимально возможная производительность.

Преимущества

Высочайшая производительность

Все данные Redis находятся в оперативной памяти сервера, в отличие от большинства систем управления базами данных, в которых данные хранятся на жестких дисках или твердотельных накопителях (SSD). Размещаемые в памяти базы данных, такие как Redis, не требуют доступа к дисковым накопителям, что позволяет избежать потерь времени на поиск. Доступ к данным можно организовать при помощи более простых алгоритмов, в которых используется меньшее количество инструкций ЦПУ. Для выполнения типовых операций требуется менее миллисекунды.

Структуры данных в памяти

Redis позволяет пользователям хранить ключи, привязанные к различным типам данных. Основной тип данных – это строка, которая может состоять из текстовых или двоичных данных размером до 512 МБ. Redis также поддерживает списки строк (List of Strings), упорядоченные в порядке вставки; множества неупорядоченных строк (Sets of unordered Strings); упорядоченные по результату множества (Sorted Sets); хеш-таблицы (Hashes), содержащие список полей и значений, и тип данных HyperLogLogs для подсчета уникальных элементов в наборе данных. С помощью Redis в памяти можно хранить практически любые типы данных.

Универсальность и простота использования

Redis поставляется с несколькими инструментами, ускоряющими и облегчающими разработку и эксплуатацию, включая шаблон «издатель-подписчик», для публикации сообщений в логических каналах, доставляемых подписчикам (хорошо подходит для чатов и систем обмена сообщениями);TTL: ключи могут иметь определенное время жизни (TTL), после чего они самостоятельно уничтожаются, это используется, чтобы избежать заполнения базы данных ненужными данными; атомарные счетчики, которые обеспечивают непротиворечивость результатов в ситуации состязания; а также Lua, мощный, но несложный язык скриптов.

Репликация и сохранность

В Redis применяется архитектура «ведущий–подчиненный» и поддерживается асинхронная репликация, при которой данные могут реплицироваться на несколько подчиненных серверов. Это обеспечивает как улучшенные характеристики чтения (так как запросы могут быть распределены между серверами), так и восстановление при отключении основного сервера.

Для обеспечения надежности Redis поддерживает как снимки состояния на момент времени (копирование наборов данных Redis на диски), так и создание файла только для добавления (AOF) для последовательной записи на диск всех изменений данных. Любой из этих методов обеспечивает быстрое восстановление данных Redis в случае сбоя.

Поддержка удобного языка разработки

Для разработчиков под Redis доступны более ста клиентов с открытым исходным кодом. Поддерживаемые языки программирования включают Java, Python, PHP, Node.js, Go и многие другие.

7. Redis. Настройка, тюнинг, репликация

Redis может запускаться без файла конфигурации с использованием встроенной конфигурации по умолчанию, однако эта настройка рекомендуется только для тестирования и разработки.

Правильный способ настройки Redis заключается в предоставлении файла конфигурации Redis, обычно называемого redis.conf.

Файл redis.conf содержит ряд директив, которые имеют очень простой формат указанный на слайде, для параметров содержащих пробелы необходимо использовать двойные кавычки

С версии Redis 2.6 можно также передать параметры конфигурации напрямую с помощью командной строки. Это очень полезно для тестирования. На слайде показан пример, который запускает новый экземпляр Redis с использованием порта 6380 как подчиненный экземпляр экземпляра, работающего на localhost порт 6379.

Изменение конфигурации Redis во время работы сервера

В Redis существует возможность переконфигурировать сервер «на лету» без остановки и перезапуска, или запросить текущую конфигурацию, используя специальные команды CONFIG SET и CONFIG GET

На лету поменять можно не все директивы конфигурации, но большинство из них поддерживаются. Для получения полной информации  по поддерживаемым параметрами смотрите в офф доку.

Также следует упомянуть что изменение конфигурации «на лету» не влияет на файл redis.conf, поэтому при следующем перезапуске Redis вместо него будет использоваться старая конфигурация. Это значит что когда вы меняете конфигурацию на работающем сервере не забывайте дублировать изменения в redis.conf. С версии Redis 2.8 появилась опция CONFIG REWRITE которая позволяет также автоматически записывать изменения в конфиг redis.conf при изменении параметров на работающем сервере.

Тюнинг Redis

Переходим к оптимизации работы Redis, даже с базовыми параметрами Redis отлично справляется с огромными нагрузками. Наиболее частая проблема с которой мы сталкиваемся да и наверняка многие тоже это подвисание редиса и большая нагрузка на диски во время сброса данных на диск. 

Решается проблема следующим образом, во первых нужно увеличить интервал времени запуска BGSAVE процесса который сбрасывает данные на диск а так же включить опцию no-appendfsync-on-rewrite yes тем самым указав что во время работы BGSAVE (создания снапшота) не будет дописываться ещё и AOF файл (он дописывается каждую секунду если стоит appendfsync everysec), так как одновременная их работа поднимает нагрузку на редис и он перестает отвечать какое-то время.

Увеличивать стоит если в redis хранятся не сильно важные данные, такие как кэш. Если данные важные но от нагрузки нужно избавиться - поднимите слейв и сохраняйте данные на нем.

 Еще одним наиболее частым сценарием при котором проявляются проблемы с редис - количество подключений. Тюнить следует параметр ядра tcp_max_tw_buckets и tcp-backlog в конфиге Redis, для начала в два раза и далее по необходимости

Репликация

Redis поддерживает репликацию типа master-slave. Данные с любого сервера Redis могут реплицироваться произвольное количество раз. Репликация полезна для масштабирования чтения (но не записи) или при очень больших объёмах данных. Все данные, которые попадают на один узел Redis (который называется master), будут попадать также на другие узлы (называются slave). Для конфигурирования slave-узлов можно изменить опцию slaveof или аналогичную по написанию команду (узлы, запущенные без подобных опций, являются master-узлами).

Репликация помогает защитить данные, копируя их на другие сервера. Репликация также может быть использована для увеличения производительности, так как запросы на чтение могут обслуживаться slave-узлами. Эти узлы могут ответить слегка устаревшими данными, но для большинства приложений это приемлемо.

Система репликации Redis ещё не поддерживает автоматическую отказоустойчивость. Если master-узел выходит из строя, необходимо вручную выбрать новый master из списка slave-узлов. Если необходимо добиться отказоустойчивости рекомендуется использовать Redis Sentinel для мониторинга и автоматического переключения master-узлов.

Redis Sentinel — это система, разработанная для помощи в управлении узлами Redis, выполняющая следующие задачи:

* Мониторинг: постоянно проверяется, что ведущий и ведомые узлы работают так, как ожидается;
* Уведомление: сообщает системному администратору или другой программе о том, что с отслеживаемыми узлами что-то не так;
* Автоматическое переключение: если ведущий узел не работает так, как ожидается, Sentinel может начать процесс восстановления работоспособности, в котором один из ведомых узлов объявляется как ведущий, другие ведомые узлы меняют конфигурацию на использование нового ведущего и приложение информируется об использовании нового адреса ведущего узла;
* Поставщик конфигурации: сообщение клиентам и другим Redis-узлам адрес текущего ведущего узла, в случае отказа Sentinel сообщает новый адрес.

Redis Sentinel входит в состав Redis начиная с версии 2.6 (Sentinel 1 — устарел). Начиная с версии Redis 2.8 поставляется текущая версия — Sentinel 2.
Sentinel не рекомендуется использовать в единственном экземпляре, кластер Sentinel-узлов поддерживает кворум, благодаря чему сохраняет работоспособность даже при переменном составе и временном отсутствии некоторых из них.

Настройку кластера мы рассматривать не будем поскольку это займет достаточно много времени, приведу лишь ссылку на официальную документацию по которой у вас не составит труда поднять полноценный Redis кластер.

